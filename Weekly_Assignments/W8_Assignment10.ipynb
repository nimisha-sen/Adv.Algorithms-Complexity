{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 10\n",
    "Let's start by implementing the binary linear classification model using logistic regression and stochastic gradient descent.\n",
    "\n",
    "Firstly, we'll load the mushroom dataset and prepare it for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data_encoded \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Mapping 'p' (poisonous) to 1 and 'e' (edible) to 0\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m data_encoded[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_encoded[\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmap({\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Splitting features and target variable\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m X \u001b[39m=\u001b[39m data_encoded\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "names = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment',\n",
    "         'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "         'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color',\n",
    "         'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "data = pd.read_csv(url, names=names)\n",
    "\n",
    "# Let's convert categorical variables to numerical using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data)\n",
    "\n",
    "# Mapping 'p' (poisonous) to 1 and 'e' (edible) to 0\n",
    "data_encoded['class'] = data_encoded['class'].map({'p': 1, 'e': 0})\n",
    "\n",
    "# Splitting features and target variable\n",
    "X = data_encoded.drop('class', axis=1)\n",
    "y = data_encoded['class']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define the logistic regression model, its gradient descent function, and train the model on the mushroom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Instantiate and train the logistic regression model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m model \u001b[39m=\u001b[39m LogisticRegression(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, n_iterations\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nimishasen/Desktop/MSc/Adv.Algorithms_Complexity/Weekly_Assignments/W8_Assignment10.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights and bias\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Compute predicted probabilities\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self.sigmoid(linear_model)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self.sigmoid(linear_model)\n",
    "        return [1 if i > 0.5 else 0 for i in y_pred]\n",
    "\n",
    "# Instantiate and train the logistic regression model\n",
    "model = LogisticRegression(learning_rate=0.1, n_iterations=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a logistic regression model, fits it to the training data, makes predictions on the test set, and evaluates its accuracy using scikit-learn's accuracy_score and classification_report functions.\n",
    "\n",
    "This approach uses a basic logistic regression model with stochastic gradient descent for binary classification of mushrooms into poisonous or edible categories based on the provided dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
